{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import ElectraConfig, ElectraTokenizerFast, ElectraForMaskedLM, ElectraForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuraton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Vanilla ELECTRA settings\\n'adam_bias_correction': False,\\n'schedule': 'original_linear',\\n'sampling': 'fp32_gumbel',\\n'electra_mask_style': True,\\n'gen_smooth_label': False,\\n'disc_smooth_label': False,\\n'size': 'small',\\n'datas': ['openwebtext'],\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = MyConfig({\n",
    "    'device': 'cuda:0',\n",
    "    'base_run_name': 'vanilla',  # run_name = {base_run_name}_{seed}\n",
    "    'seed': 11081,  # 11081 36 1188 76 1 4 4649 7 # None/False to randomly choose seed from [0,999999]\n",
    "\n",
    "    'adam_bias_correction': False,\n",
    "    'schedule': 'original_linear',\n",
    "    'sampling': 'fp32_gumbel',\n",
    "    'electra_mask_style': True,\n",
    "    'gen_smooth_label': False,\n",
    "    'disc_smooth_label': False,\n",
    "\n",
    "    'size': 'small',\n",
    "#     'datas': ['openwebtext'],\n",
    "    'datas': ['wikipedia'],\n",
    "    'logger': \"wandb\",\n",
    "    'num_workers': 3,\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\" Vanilla ELECTRA settings\n",
    "'adam_bias_correction': False,\n",
    "'schedule': 'original_linear',\n",
    "'sampling': 'fp32_gumbel',\n",
    "'electra_mask_style': True,\n",
    "'gen_smooth_label': False,\n",
    "'disc_smooth_label': False,\n",
    "'size': 'small',\n",
    "'datas': ['openwebtext'],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process id: 12434\n",
      "{'device': 'cuda:0', 'base_run_name': 'vanilla', 'seed': 11081, 'adam_bias_correction': False, 'schedule': 'original_linear', 'sampling': 'fp32_gumbel', 'electra_mask_style': True, 'gen_smooth_label': False, 'disc_smooth_label': False, 'size': 'small', 'datas': ['wikipedia'], 'logger': 'wandb', 'num_workers': 3, 'run_name': 'vanilla_11081', 'mask_prob': 0.15, 'lr': 0.0005, 'bs': 128, 'steps': 1000000, 'max_length': 128}\n"
     ]
    }
   ],
   "source": [
    "# Check and Default\n",
    "assert c.sampling in ['fp32_gumbel', 'fp16_gumbel', 'multinomial']\n",
    "assert c.schedule in ['original_linear', 'separate_linear', 'one_cycle', 'adjusted_one_cycle']\n",
    "for data in c.datas:\n",
    "    assert data in ['wikipedia', 'bookcorpus', 'openwebtext']\n",
    "assert c.logger in ['wandb', 'neptune', None, False]\n",
    "\n",
    "if not c.base_run_name:\n",
    "    c.base_run_name = str(datetime.now(timezone(timedelta(hours=+8))))[6:-13].replace(' ','').replace(':','').replace('-','')\n",
    "if not c.seed:\n",
    "    c.seed = random.randint(0, 999999)\n",
    "\n",
    "c.run_name = f'{c.base_run_name}_{c.seed}'\n",
    "\n",
    "if c.gen_smooth_label is True:\n",
    "    c.gen_smooth_label = 0.1\n",
    "if c.disc_smooth_label is True:\n",
    "    c.disc_smooth_label = 0.1\n",
    "\n",
    "# Setting of different sizes\n",
    "i = ['small', 'base', 'large'].index(c.size)\n",
    "c.mask_prob = [0.15, 0.15, 0.25][i]\n",
    "c.lr = [5e-4, 2e-4, 2e-4][i]\n",
    "c.bs = [128, 256, 2048][i]\n",
    "c.steps = [10**6, 766*1000, 400*1000][i]\n",
    "c.max_length = [128, 512, 512][i]\n",
    "generator_size_divisor = [4, 3, 4][i]\n",
    "\n",
    "disc_config = ElectraConfig.from_pretrained(f'google/electra-{c.size}-discriminator')\n",
    "gen_config = ElectraConfig.from_pretrained(f'google/electra-{c.size}-generator')\n",
    "# note that public electra-small model is actually small++ and don't scale down generator size \n",
    "gen_config.hidden_size = int(disc_config.hidden_size/generator_size_divisor)\n",
    "gen_config.num_attention_heads = disc_config.num_attention_heads//generator_size_divisor\n",
    "gen_config.intermediate_size = disc_config.intermediate_size//generator_size_divisor\n",
    "hf_tokenizer = ElectraTokenizerFast.from_pretrained(f\"google/electra-{c.size}-generator\")\n",
    "\n",
    "# Path to data\n",
    "Path('./datasets').mkdir(exist_ok=True)\n",
    "Path('./checkpoints/pretrain').mkdir(exist_ok=True, parents=True)\n",
    "edl_cache_dir = Path(\"./datasets/electra_dataloader\")\n",
    "edl_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Print info\n",
    "print(f\"process id: {os.getpid()}\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='google/electra-small-generator', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load/download wiki dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikipedia (./datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load/create data from wiki dataset for ELECTRA\n",
      "cache_file_name 1000_electra_wiki_128.arrow\n",
      "cache_file_name /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00000_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00001_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00002_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00003_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00004_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00005_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00006_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00007_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00008_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00009_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00010_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00011_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00012_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00013_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00014_of_00016.arrow\n",
      "Loading cached processed dataset at /home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/datasets/wikipedia/20200501.en/1.0.0/4021357e28509391eab2f8300d9b689e7e8f3a877ebb3d354b01577d497ebc63/1000_electra_wiki_128_00015_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from download_datasets import download_dset\n",
    "\n",
    "train_dset = download_dset(c, hf_tokenizer, cache_dir='./datasets', num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dset Dataset({\n",
      "    features: ['first_segment', 'input_ids', 'second_segment', 'sentA_length'],\n",
      "    num_rows: 20344249\n",
      "})\n",
      "HF_Dataset\n",
      "cols {'input_ids': <class 'fastai.text.data.TensorText'>, 'sentA_length': <function get_dataloader.<locals>.<lambda> at 0x7f31777b0e50>}\n",
      "n_inp 2\n",
      "MySortedDL\n",
      "pad_idx 0\n",
      "pad_idxs [0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miyamonz/.cache/pypoetry/virtualenvs/electra-pytorch-3wiafTge-py3.8/lib/python3.8/site-packages/datasets/arrow_dataset.py:851: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from get_dataloaders import get_dataloader\n",
    "dl = get_dataloader(c, hf_tokenizer, train_dset, device='cpu')\n",
    "\n",
    "from fastai.text.all import DataLoaders\n",
    "dls = DataLoaders(dl, path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158940"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f31d91459b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed & PyTorch benchmark\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dls[0].rng = random.Random(c.seed) # for fastai dataloader\n",
    "random.seed(c.seed)\n",
    "np.random.seed(c.seed)\n",
    "torch.manual_seed(c.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and Discriminator\n",
    "generator = ElectraForMaskedLM(gen_config)\n",
    "discriminator = ElectraForPreTraining(disc_config)\n",
    "discriminator.electra.embeddings = generator.electra.embeddings\n",
    "generator.generator_lm_head.weight = generator.electra.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from pl_model import LitElectra\n",
    "model = LitElectra(generator, discriminator, hf_tokenizer, sampling=c.sampling, config=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiyamonz\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wise-wind-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/miyamonz/electra_pytorch-pretrain\" target=\"_blank\">https://wandb.ai/miyamonz/electra_pytorch-pretrain</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/miyamonz/electra_pytorch-pretrain/runs/1w8pg5uv\" target=\"_blank\">https://wandb.ai/miyamonz/electra_pytorch-pretrain/runs/1w8pg5uv</a><br/>\n",
       "                Run data is saved locally in <code>/home/miyamonz/ghq/github.com/miyamonz/electra_pytorch/pretrain/wandb/run-20210218_163536-1w8pg5uv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                  | Params\n",
      "--------------------------------------------------------\n",
      "0 | generator     | ElectraForMaskedLM    | 4.6 M \n",
      "1 | discriminator | ElectraForPreTraining | 13.5 M\n",
      "--------------------------------------------------------\n",
      "14.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.2 M    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6b62c20e644c69803a604b2864e008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miyamonz/.cache/pypoetry/virtualenvs/electra-pytorch-3wiafTge-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/miyamonz/.cache/pypoetry/virtualenvs/electra-pytorch-3wiafTge-py3.8/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(gpus=1, gradient_clip_val=1., precision=16,\n",
    "                     logger=wandb_logger,\n",
    "                     log_every_n_steps=1,\n",
    "                    )\n",
    "trainer.fit(model, dl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from fastai.text.all import Learner\n",
    "from _utils.would_like_to_pr import RunSteps\n",
    "# Learner\n",
    "dls.to(torch.device(c.device))\n",
    "learn = Learner(dls, electra_model,\n",
    "                loss_func=electra_loss_func,\n",
    "                opt_func=opt_func,\n",
    "                path='./checkpoints',\n",
    "                model_dir='pretrain',\n",
    "                cbs=[mlm_cb,\n",
    "                    RunSteps(c.steps, [0.0625, 0.125, 0.25, 0.5, 1.0], c.run_name+\"_{percent}\"),\n",
    "                    ],\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
